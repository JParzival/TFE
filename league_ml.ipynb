{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                                MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que se debe de hacer es un centrado y escalado de los datos, eliminando previamente datos que no necesito para ML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe para predecir\n",
    "\n",
    "games = pd.read_csv(\"data/games_clean.csv\")\n",
    "\n",
    "games_ml = games.iloc[:, -56:]\n",
    "games_ml['Duration'] = games.gameDuration\n",
    "columnas = games_ml.columns\n",
    "\n",
    "#Mi variable a predecir (target)\n",
    "\n",
    "winner_ml = games.iloc[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora el primer paso es convertir todas las variables de campeones y spells a dummies, puesto que son texto\n",
    "\n",
    "games_ml = pd.get_dummies(games_ml)\n",
    "\n",
    "# Ahora que lo tengo tengo que hacer el centrado y escalado para evitar condicionar a la red con valores grandes\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "games_ml_scaled = scale(games_ml, axis=0, with_mean=True, with_std=True, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(games_ml_scaled) # Calculamos la varianza de las componentes principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lo mostramos \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Número de componentes')\n",
    "plt.ylabel('Varianza en porcentaje (%)')\n",
    "plt.title('Varianza explicada')\n",
    "plt.savefig(\"imagenes/PCA.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver que nos podemos quitar 500 dimensiones sin problemas siguiendo con una varianza bastante decente...\n",
    "\n",
    "Lo dejaré en que con el 90% de explicación me vale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []\n",
    "\n",
    "pca = PCA(0.9)\n",
    "\n",
    "componentes_principales = pca.fit_transform(games_ml_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "for n in range(componentes_principales.shape[1]):\n",
    "    list.append(\"PC {:.0f}\".format(n))\n",
    "    \n",
    "dataframe_ml_09 = pd.DataFrame(data = componentes_principales, columns = list)\n",
    "dataframe_ml_09.head(2)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataframe_ml_09, games.winner, test_size=0.30, random_state=97)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crearé también un PCA con 50% de variación para las grandes reducciones de dimensionalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_2 = []\n",
    "\n",
    "pca_low = PCA(0.5)\n",
    "\n",
    "componentes_principales_low = pca_low.fit_transform(games_ml_scaled)\n",
    "\n",
    "for n in range(componentes_principales_low.shape[1]):\n",
    "    list_2.append(\"PC {:.0f}\".format(n))\n",
    "    \n",
    "dataframe_ml_low = pd.DataFrame(data = componentes_principales_low, columns = list_2)\n",
    "\n",
    "dataframe_ml_low.head(2)\n",
    "\n",
    "x_train_low, x_test_low, y_train_low, y_test_low = train_test_split(dataframe_ml_low, games.winner, test_size=0.30, random_state=97)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora crearé una matriz difusa a partir de los datos originales (tras el dummy), para mejorar la eficiencia computacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La difusión de la matriz en tanto por uno es de: 0.017\n"
     ]
    }
   ],
   "source": [
    "print(\"La difusión de la matriz en tanto por uno es de: {:.3f}\".format(games_ml.astype(bool).sum(axis=1).sum(axis=0)/(games_ml.shape[0]*games_ml.shape[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es decir, se podría decir que en la matriz prácticamente todos los elementos son cero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creacióm de la matriz difusa\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "sparse_matrix = csr_matrix(games_ml)\n",
    "sparse_matrix\n",
    "\n",
    "x_train_sparse, x_test_sparse, y_train_sparse, y_test_sparse = train_test_split(sparse_matrix, games.winner, test_size=0.30, random_state=97)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tengo el centrado y escalado y el PCA, es momento de empezar con los algoritmos clasificadores y regresores:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                \n",
    "                                                                \n",
    "                                                                1) Redes Neuronales - Perceptrón Multicapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "df_resultados = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lbfgs para datasets pequeños, converge mejor. adam para grandes, converge peor\n",
    "\n",
    "# Solver lento pero mejor, alpha (decay) pequeño, seed en 1, activación por ReLU y 50 neuronas en la capa intermedia\n",
    "\n",
    "red_multicapa_50 = MLPClassifier(solver='lbfgs', alpha=0.001, random_state=1, activation = 'relu', hidden_layer_sizes=(50,))\n",
    "red_multicapa_50.fit(x_train, y_train)\n",
    "prediccion_red_multicapa_50 = red_multicapa_50.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 NEURONAS\n",
      "La puntuación del entrenamiento en tanto por 1 es de: 1.000\n",
      "La puntuación del test en tanto por 1 es de: 0.917\n"
     ]
    }
   ],
   "source": [
    "print(\"50 NEURONAS\")\n",
    "print(\"La puntuación del entrenamiento en tanto por 1 es de: {:.3f}\".format(red_multicapa_50.score(x_train, y_train)))\n",
    "print(\"La puntuación del test en tanto por 1 es de: {:.3f}\".format(red_multicapa_50.score(x_test, y_test)))\n",
    "\n",
    "df_resultados['50 Neuronas_Train'] = red_multicapa_50.score(x_train, y_train)\n",
    "df_resultados['50 Neuronas_Test'] = red_multicapa_50.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión\n",
      "[[7188  598]\n",
      " [ 686 6975]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Matriz de confusión\")\n",
    "print(confusion_matrix(y_test,prediccion_red_multicapa_50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.91      0.92      0.92      7786\n",
      "          2       0.92      0.91      0.92      7661\n",
      "\n",
      "avg / total       0.92      0.92      0.92     15447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,prediccion_red_multicapa_50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se está cayendo en overfitting. Reducción de las neuronas de la capa intermedia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_multicapa_20 = MLPClassifier(solver='lbfgs', alpha=0.001, random_state=1, activation = 'relu', hidden_layer_sizes=(20,))\n",
    "red_multicapa_20.fit(x_train, y_train)\n",
    "prediccion_red_multicapa_20 = red_multicapa_20.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 NEURONAS\n",
      "La puntuación del entrenamiento en tanto por 1 es de: 1.000\n",
      "La puntuación del test en tanto por 1 es de: 0.914\n"
     ]
    }
   ],
   "source": [
    "print(\"20 NEURONAS\")\n",
    "print(\"La puntuación del entrenamiento en tanto por 1 es de: {:.3f}\".format(red_multicapa_20.score(x_train, y_train)))\n",
    "print(\"La puntuación del test en tanto por 1 es de: {:.3f}\".format(red_multicapa_20.score(x_test, y_test)))\n",
    "\n",
    "df_resultados['20 Neuronas_Train'] = red_multicapa_20.score(x_train, y_train)\n",
    "df_resultados['20 Neuronas_Test'] = red_multicapa_20.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión\n",
      "[[7150  636]\n",
      " [ 698 6963]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Matriz de confusión\")\n",
    "print(confusion_matrix(y_test,prediccion_red_multicapa_20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.91      0.92      0.91      7786\n",
      "          2       0.92      0.91      0.91      7661\n",
      "\n",
      "avg / total       0.91      0.91      0.91     15447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,prediccion_red_multicapa_20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigue estando el entrenamiento demasiado alto, demasiado overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_multicapa_10 = MLPClassifier(solver='lbfgs', alpha=0.001, random_state=1, activation = 'relu', hidden_layer_sizes=(10,))\n",
    "red_multicapa_10.fit(x_train, y_train)\n",
    "prediccion_red_multicapa_10 = red_multicapa_10.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 NEURONAS\n",
      "La puntuación del entrenamiento en tanto por 1 es de: 0.997\n",
      "La puntuación del test en tanto por 1 es de: 0.912\n"
     ]
    }
   ],
   "source": [
    "print(\"10 NEURONAS\")\n",
    "print(\"La puntuación del entrenamiento en tanto por 1 es de: {:.3f}\".format(red_multicapa_10.score(x_train, y_train)))\n",
    "print(\"La puntuación del test en tanto por 1 es de: {:.3f}\".format(red_multicapa_10.score(x_test, y_test)))\n",
    "\n",
    "df_resultados['10 Neuronas_Train'] = red_multicapa_10.score(x_train, y_train)\n",
    "df_resultados['10 Neuronas_Test'] = red_multicapa_10.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión\n",
      "[[7113  673]\n",
      " [ 689 6972]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Matriz de confusión\")\n",
    "print(confusion_matrix(y_test,prediccion_red_multicapa_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.91      0.91      0.91      7786\n",
      "          2       0.91      0.91      0.91      7661\n",
      "\n",
      "avg / total       0.91      0.91      0.91     15447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,prediccion_red_multicapa_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_multicapa_10_d01 = MLPClassifier(solver='adam', alpha=0.001, random_state=1, activation = 'relu', hidden_layer_sizes=(10,), learning_rate_init=0.1)\n",
    "red_multicapa_10_d01.fit(x_train, y_train)\n",
    "prediccion_red_multicapa_10_d01 = red_multicapa_10_d01.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 NEURONAS, DECAY 0.1\n",
      "La puntuación del entrenamiento en tanto por 1 es de: 0.935\n",
      "La puntuación del test en tanto por 1 es de: 0.886\n"
     ]
    }
   ],
   "source": [
    "print(\"10 NEURONAS, DECAY 0.1\")\n",
    "print(\"La puntuación del entrenamiento en tanto por 1 es de: {:.3f}\".format(red_multicapa_10_d01.score(x_train, y_train)))\n",
    "print(\"La puntuación del test en tanto por 1 es de: {:.3f}\".format(red_multicapa_10_d01.score(x_test, y_test)))\n",
    "\n",
    "df_resultados['10 Neuronas-Decay 0.1_Train'] = red_multicapa_10_d01.score(x_train, y_train)\n",
    "df_resultados['10 Neuronas-Decay 0.1_Test'] = red_multicapa_10_d01.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión\n",
      "[[6558 1228]\n",
      " [ 537 7124]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Matriz de confusión\")\n",
    "print(confusion_matrix(y_test,prediccion_red_multicapa_10_d01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.92      0.84      0.88      7786\n",
      "          2       0.85      0.93      0.89      7661\n",
      "\n",
      "avg / total       0.89      0.89      0.89     15447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,prediccion_red_multicapa_10_d01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                            2) KNN - K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN tiene un problema con la alta dimensionalidad, puesto que se basa en distancias euclídeas. Debido a esto, tengo que hacer una reducción de la dimensionalidad aún más grande a costa de sacrificar precisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como tenemos dos tipos de partidas (ganadas por T1 y ganadas por T2), vamos a clasificar en dos...\n",
    "\n",
    "Para empezar, iré con K = 5, aunque seguramente acabe en overfitting y haya que subir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "knn.fit(x_train_sparse, y_train_sparse)\n",
    "prediccion_knn5 = knn.predict(x_test_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN con K = 5\n",
      "La puntuación del entrenamiento en tanto por 1 es de: 0.967\n",
      "La puntuación del test en tanto por 1 es de: 0.948\n"
     ]
    }
   ],
   "source": [
    "score_train_knn_5 = knn.score(x_train_sparse, y_train_sparse)\n",
    "score_test_knn_5  = knn.score(x_test_sparse, y_test_sparse)\n",
    "\n",
    "print(\"KNN con K = 5\")\n",
    "print(\"La puntuación del entrenamiento en tanto por 1 es de: {:.3f}\".format(score_train_knn_5))\n",
    "print(\"La puntuación del test en tanto por 1 es de: {:.3f}\".format(score_test_knn_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7401  385]\n",
      " [ 425 7236]]\n"
     ]
    }
   ],
   "source": [
    "df_resultados['knn5_train'] = score_train_knn_5\n",
    "df_resultados['knn5_test'] = score_test_knn_5\n",
    "print(confusion_matrix(y_test_sparse, prediccion_knn5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La teoría dice que el K perfecto suele ser sqrt(total). Veamos a ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as m\n",
    "\n",
    "knn_sqrt = KNeighborsClassifier(n_neighbors=m.trunc(m.sqrt(x_train.shape[0])), weights='uniform')\n",
    "knn_sqrt.fit(x_train_sparse, y_train_sparse)\n",
    "prediccion_knn_sqrt = knn_sqrt.predict(x_test_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN con K = 124\n",
      "La puntuación del entrenamiento en tanto por 1 es de: 0.928\n",
      "La puntuación del test en tanto por 1 es de: 0.921\n"
     ]
    }
   ],
   "source": [
    "score_train_knn_sqrt = knn_sqrt.score(x_train_sparse, y_train_sparse)\n",
    "score_test_knn_sqrt  = knn_sqrt.score(x_test_sparse, y_test_sparse)\n",
    "\n",
    "print(\"KNN con K = {:.0f}\".format(m.sqrt(x_train.shape[0])))\n",
    "print(\"La puntuación del entrenamiento en tanto por 1 es de: {:.3f}\".format(score_train_knn_sqrt))\n",
    "print(\"La puntuación del test en tanto por 1 es de: {:.3f}\".format(score_test_knn_sqrt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7307  479]\n",
      " [ 738 6923]]\n"
     ]
    }
   ],
   "source": [
    "df_resultados['knn_sqrt_train'] = score_train_knn_sqrt\n",
    "df_resultados['knn_sqrt_test'] = score_test_knn_sqrt\n",
    "print(confusion_matrix(y_test_sparse, prediccion_knn_sqrt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver, en este caso la precisión es inferior con sqrt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
