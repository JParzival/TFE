{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                                MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que se debe de hacer es un centrado y escalado de los datos, eliminando previamente datos que no necesito para ML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe para predecir\n",
    "\n",
    "games = pd.read_csv(\"data/games_clean.csv\")\n",
    "\n",
    "games_ml = games.iloc[:, -56:]\n",
    "games_ml['Duration'] = games.gameDuration\n",
    "columnas = games_ml.columns\n",
    "\n",
    "#Mi variable a predecir (target)\n",
    "\n",
    "winner_ml = games.iloc[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\jorge\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by the scale function.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Ahora el primer paso es convertir todas las variables de campeones y spells a dummies, puesto que son texto\n",
    "\n",
    "games_ml = pd.get_dummies(games_ml)\n",
    "\n",
    "# Ahora que lo tengo tengo que hacer el centrado y escalado para evitar condicionar a la red con valores grandes\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "games_ml_scaled = scale(games_ml, axis=0, with_mean=True, with_std=True, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(games_ml_scaled) # Calculamos la varianza de las componentes principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lo mostramos \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Número de componentes')\n",
    "plt.ylabel('Varianza en porcentaje (%)')\n",
    "plt.title('Varianza explicada')\n",
    "plt.savefig(\"imagenes/PCA.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver que nos podemos quitar 500 dimensiones sin problemas siguiendo con una varianza bastante decente...\n",
    "\n",
    "Lo dejaré en que con el 90% de explicación me vale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []\n",
    "\n",
    "pca = PCA(0.9)\n",
    "\n",
    "componentes_principales = pca.fit_transform(games_ml_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "for n in range(componentes_principales.shape[1]):\n",
    "    list.append(\"PC {:.0f}\".format(n))\n",
    "    \n",
    "dataframe_ml_09 = pd.DataFrame(data = componentes_principales, columns = list)\n",
    "dataframe_ml_09.head(2)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataframe_ml_09, games.winner, test_size=0.30, random_state=97)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crearé también un PCA con 50% de variación para las grandes reducciones de dimensionalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_2 = []\n",
    "\n",
    "pca_low = PCA(0.5)\n",
    "\n",
    "componentes_principales_low = pca_low.fit_transform(games_ml_scaled)\n",
    "\n",
    "for n in range(componentes_principales_low.shape[1]):\n",
    "    list_2.append(\"PC {:.0f}\".format(n))\n",
    "    \n",
    "dataframe_ml_low = pd.DataFrame(data = componentes_principales_low, columns = list_2)\n",
    "\n",
    "dataframe_ml_low.head(2)\n",
    "\n",
    "x_train_low, x_test_low, y_train_low, y_test_low = train_test_split(dataframe_ml_low, games.winner, test_size=0.30, random_state=97)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora crearé una matriz difusa a partir de los datos originales (tras el dummy), para mejorar la eficiencia computacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La difusión de la matriz en tanto por uno es de: 0.017\n"
     ]
    }
   ],
   "source": [
    "print(\"La difusión de la matriz en tanto por uno es de: {:.3f}\".format(games_ml.astype(bool).sum(axis=1).sum(axis=0)/(games_ml.shape[0]*games_ml.shape[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es decir, se podría decir que en la matriz prácticamente todos los elementos son cero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creacióm de la matriz difusa\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "sparse_matrix = csr_matrix(games_ml)\n",
    "sparse_matrix\n",
    "\n",
    "x_train_sparse, x_test_sparse, y_train_sparse, y_test_sparse = train_test_split(sparse_matrix, games.winner, test_size=0.30, random_state=97)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tengo el centrado y escalado y el PCA, es momento de empezar con los algoritmos clasificadores y regresores:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                \n",
    "                                                                \n",
    "                                                                1) Redes Neuronales - Perceptrón Multicapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "df_resultados = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lbfgs para datasets pequeños, converge mejor. adam para grandes, converge peor\n",
    "\n",
    "# Solver lento pero mejor, alpha (decay) pequeño, seed en 1, activación por ReLU y 50 neuronas en la capa intermedia\n",
    "\n",
    "red_multicapa_50 = MLPClassifier(solver='lbfgs', alpha=0.001, random_state=1, activation = 'relu', hidden_layer_sizes=(50,))\n",
    "red_multicapa_50.fit(x_train, y_train)\n",
    "prediccion_red_multicapa_50 = red_multicapa_50.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 NEURONAS\n",
      "La puntuación del entrenamiento en tanto por 1 es de: 1.000\n",
      "La puntuación del test en tanto por 1 es de: 0.917\n"
     ]
    }
   ],
   "source": [
    "print(\"50 NEURONAS\")\n",
    "print(\"La puntuación del entrenamiento en tanto por 1 es de: {:.3f}\".format(red_multicapa_50.score(x_train, y_train)))\n",
    "print(\"La puntuación del test en tanto por 1 es de: {:.3f}\".format(red_multicapa_50.score(x_test, y_test)))\n",
    "\n",
    "df_resultados['50 Neuronas_Train'] = red_multicapa_50.score(x_train, y_train)\n",
    "df_resultados['50 Neuronas_Test'] = red_multicapa_50.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión\n",
      "[[7188  598]\n",
      " [ 686 6975]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Matriz de confusión\")\n",
    "print(confusion_matrix(y_test,prediccion_red_multicapa_50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.92      0.92      7786\n",
      "           2       0.92      0.91      0.92      7661\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     15447\n",
      "   macro avg       0.92      0.92      0.92     15447\n",
      "weighted avg       0.92      0.92      0.92     15447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,prediccion_red_multicapa_50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se está cayendo en overfitting. Reducción de las neuronas de la capa intermedia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_multicapa_20 = MLPClassifier(solver='lbfgs', alpha=0.001, random_state=1, activation = 'relu', hidden_layer_sizes=(20,))\n",
    "red_multicapa_20.fit(x_train, y_train)\n",
    "prediccion_red_multicapa_20 = red_multicapa_20.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 NEURONAS\n",
      "La puntuación del entrenamiento en tanto por 1 es de: 1.000\n",
      "La puntuación del test en tanto por 1 es de: 0.914\n"
     ]
    }
   ],
   "source": [
    "print(\"20 NEURONAS\")\n",
    "print(\"La puntuación del entrenamiento en tanto por 1 es de: {:.3f}\".format(red_multicapa_20.score(x_train, y_train)))\n",
    "print(\"La puntuación del test en tanto por 1 es de: {:.3f}\".format(red_multicapa_20.score(x_test, y_test)))\n",
    "\n",
    "df_resultados['20 Neuronas_Train'] = red_multicapa_20.score(x_train, y_train)\n",
    "df_resultados['20 Neuronas_Test'] = red_multicapa_20.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión\n",
      "[[7150  636]\n",
      " [ 698 6963]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Matriz de confusión\")\n",
    "print(confusion_matrix(y_test,prediccion_red_multicapa_20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.92      0.91      7786\n",
      "           2       0.92      0.91      0.91      7661\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     15447\n",
      "   macro avg       0.91      0.91      0.91     15447\n",
      "weighted avg       0.91      0.91      0.91     15447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,prediccion_red_multicapa_20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigue estando el entrenamiento demasiado alto, demasiado overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_multicapa_10 = MLPClassifier(solver='lbfgs', alpha=0.001, random_state=1, activation = 'relu', hidden_layer_sizes=(10,))\n",
    "red_multicapa_10.fit(x_train, y_train)\n",
    "prediccion_red_multicapa_10 = red_multicapa_10.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 NEURONAS\n",
      "La puntuación del entrenamiento en tanto por 1 es de: 0.997\n",
      "La puntuación del test en tanto por 1 es de: 0.912\n"
     ]
    }
   ],
   "source": [
    "print(\"10 NEURONAS\")\n",
    "print(\"La puntuación del entrenamiento en tanto por 1 es de: {:.3f}\".format(red_multicapa_10.score(x_train, y_train)))\n",
    "print(\"La puntuación del test en tanto por 1 es de: {:.3f}\".format(red_multicapa_10.score(x_test, y_test)))\n",
    "\n",
    "df_resultados['10 Neuronas_Train'] = red_multicapa_10.score(x_train, y_train)\n",
    "df_resultados['10 Neuronas_Test'] = red_multicapa_10.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión\n",
      "[[7113  673]\n",
      " [ 689 6972]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Matriz de confusión\")\n",
    "print(confusion_matrix(y_test,prediccion_red_multicapa_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.91      0.91      7786\n",
      "           2       0.91      0.91      0.91      7661\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     15447\n",
      "   macro avg       0.91      0.91      0.91     15447\n",
      "weighted avg       0.91      0.91      0.91     15447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,prediccion_red_multicapa_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_multicapa_10_d01 = MLPClassifier(solver='adam', alpha=0.001, random_state=1, activation = 'relu', hidden_layer_sizes=(10,), learning_rate_init=0.1)\n",
    "red_multicapa_10_d01.fit(x_train, y_train)\n",
    "prediccion_red_multicapa_10_d01 = red_multicapa_10_d01.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 NEURONAS, DECAY 0.1\n",
      "La puntuación del entrenamiento en tanto por 1 es de: 0.957\n",
      "La puntuación del test en tanto por 1 es de: 0.904\n"
     ]
    }
   ],
   "source": [
    "print(\"10 NEURONAS, DECAY 0.1\")\n",
    "print(\"La puntuación del entrenamiento en tanto por 1 es de: {:.3f}\".format(red_multicapa_10_d01.score(x_train, y_train)))\n",
    "print(\"La puntuación del test en tanto por 1 es de: {:.3f}\".format(red_multicapa_10_d01.score(x_test, y_test)))\n",
    "\n",
    "df_resultados['10 Neuronas-Decay 0.1_Train'] = red_multicapa_10_d01.score(x_train, y_train)\n",
    "df_resultados['10 Neuronas-Decay 0.1_Test'] = red_multicapa_10_d01.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión\n",
      "[[7189  597]\n",
      " [ 885 6776]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Matriz de confusión\")\n",
    "print(confusion_matrix(y_test,prediccion_red_multicapa_10_d01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.92      0.91      7786\n",
      "           2       0.92      0.88      0.90      7661\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     15447\n",
      "   macro avg       0.90      0.90      0.90     15447\n",
      "weighted avg       0.90      0.90      0.90     15447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,prediccion_red_multicapa_10_d01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                            2) KNN - K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN tiene un problema con la alta dimensionalidad, puesto que se basa en distancias euclídeas. Debido a esto, tengo que hacer una reducción de la dimensionalidad aún más grande a costa de sacrificar precisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como tenemos dos tipos de partidas (ganadas por T1 y ganadas por T2), vamos a clasificar en dos...\n",
    "\n",
    "Para empezar, iré con K = 5, aunque seguramente acabe en overfitting y haya que subir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "knn.fit(x_train_sparse, y_train_sparse)\n",
    "prediccion_knn5 = knn.predict(x_test_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN con K = 5\n",
      "La puntuación del entrenamiento en tanto por 1 es de: 0.967\n",
      "La puntuación del test en tanto por 1 es de: 0.948\n"
     ]
    }
   ],
   "source": [
    "print(\"KNN con K = 5\")\n",
    "\n",
    "score_train_knn_5 = knn.score(x_train_sparse, y_train_sparse)\n",
    "print(\"La puntuación del entrenamiento en tanto por 1 es de: {:.3f}\".format(score_train_knn_5))\n",
    "\n",
    "score_test_knn_5  = knn.score(x_test_sparse, y_test_sparse)\n",
    "print(\"La puntuación del test en tanto por 1 es de: {:.3f}\".format(score_test_knn_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7401  385]\n",
      " [ 425 7236]]\n"
     ]
    }
   ],
   "source": [
    "df_resultados['knn5_train'] = score_train_knn_5\n",
    "df_resultados['knn5_test'] = score_test_knn_5\n",
    "print(confusion_matrix(y_test_sparse, prediccion_knn5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La teoría dice que el K perfecto suele ser sqrt(total). Veamos a ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as m\n",
    "\n",
    "knn_sqrt = KNeighborsClassifier(n_neighbors=m.trunc(m.sqrt(x_train.shape[0])), weights='uniform')\n",
    "knn_sqrt.fit(x_train_sparse, y_train_sparse)\n",
    "prediccion_knn_sqrt = knn_sqrt.predict(x_test_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN con K = 190\n",
      "La puntuación del entrenamiento en tanto por 1 es de: 0.928\n",
      "La puntuación del test en tanto por 1 es de: 0.921\n"
     ]
    }
   ],
   "source": [
    "print(\"KNN con K = {:.0f}\".format(m.sqrt(x_train.shape[0])))\n",
    "\n",
    "score_train_knn_sqrt = knn_sqrt.score(x_train_sparse, y_train_sparse)\n",
    "print(\"La puntuación del entrenamiento en tanto por 1 es de: {:.3f}\".format(score_train_knn_sqrt))\n",
    "\n",
    "score_test_knn_sqrt  = knn_sqrt.score(x_test_sparse, y_test_sparse)\n",
    "print(\"La puntuación del test en tanto por 1 es de: {:.3f}\".format(score_test_knn_sqrt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7307  479]\n",
      " [ 738 6923]]\n"
     ]
    }
   ],
   "source": [
    "df_resultados['knn_sqrt_train'] = score_train_knn_sqrt\n",
    "df_resultados['knn_sqrt_test'] = score_test_knn_sqrt\n",
    "print(confusion_matrix(y_test_sparse, prediccion_knn_sqrt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver, en este caso la precisión es inferior con sqrt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que se ve que con K = 5 se obtienen buenos resultados, pivotemos alrededor.\n",
    "\n",
    "K = 3 -> Tiene riesgo de caer en overfitting, pero quizás mejore los resultados de test\n",
    "\n",
    "K = 7 -> Mayor generalización. ¿Predecirá mejor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_3 = KNeighborsClassifier(n_neighbors=3, weights='uniform')\n",
    "knn_3.fit(x_train_sparse, y_train_sparse)\n",
    "prediccion_knn3 = knn_3.predict(x_test_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN con K = 3\n",
      "La puntuación del entrenamiento en tanto por 1 es de: 0.973\n",
      "La puntuación del test en tanto por 1 es de: 0.946\n"
     ]
    }
   ],
   "source": [
    "print(\"KNN con K = 3\")\n",
    "\n",
    "score_train_knn_3 = knn_3.score(x_train_sparse, y_train_sparse)\n",
    "print(\"La puntuación del entrenamiento en tanto por 1 es de: {:.3f}\".format(score_train_knn_3))\n",
    "\n",
    "score_test_knn_3 = knn_3.score(x_test_sparse, y_test_sparse)\n",
    "print(\"La puntuación del test en tanto por 1 es de: {:.3f}\".format(score_test_knn_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7377  409]\n",
      " [ 428 7233]]\n"
     ]
    }
   ],
   "source": [
    "df_resultados['knn3_train'] = score_train_knn_3\n",
    "df_resultados['knn3_test'] = score_test_knn_3\n",
    "print(confusion_matrix(y_test_sparse, prediccion_knn3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_7 = KNeighborsClassifier(n_neighbors=7, weights='uniform')\n",
    "knn_7.fit(x_train_sparse, y_train_sparse)\n",
    "prediccion_knn7 = knn_7.predict(x_test_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN con K = 7\n",
      "La puntuación del entrenamiento en tanto por 1 es de: 0.965\n",
      "La puntuación del test en tanto por 1 es de: 0.949\n"
     ]
    }
   ],
   "source": [
    "print(\"KNN con K = 7\")\n",
    "\n",
    "score_train_knn_7 = knn_7.score(x_train_sparse, y_train_sparse)\n",
    "print(\"La puntuación del entrenamiento en tanto por 1 es de: {:.3f}\".format(score_train_knn_7))\n",
    "\n",
    "score_test_knn_7 = knn_7.score(x_test_sparse, y_test_sparse)\n",
    "print(\"La puntuación del test en tanto por 1 es de: {:.3f}\".format(score_test_knn_7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7417  369]\n",
      " [ 413 7248]]\n"
     ]
    }
   ],
   "source": [
    "df_resultados['knn7_train'] = score_train_knn_7\n",
    "df_resultados['knn7_test'] = score_test_knn_7\n",
    "print(confusion_matrix(y_test_sparse, prediccion_knn7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, voy a hacer con GridSearch una búsqueda del mejor K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_neighbors': range(3, 10)}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn', scoring='accuracy',\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_grid = KNeighborsClassifier()\n",
    "k_range = range(3, 10)\n",
    "parametros_grid = dict(n_neighbors=k_range)\n",
    "\n",
    "grid_knn = GridSearchCV(knn_grid, parametros_grid, cv=3, scoring='accuracy')\n",
    "\n",
    "grid_knn.fit(x_train_sparse, y_train_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\jorge\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\jorge\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\jorge\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\jorge\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\jorge\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.02065412, 0.01898456, 0.01932526, 0.0209868 , 0.01966914,\n",
       "        0.01965809, 0.02098854]),\n",
       " 'std_fit_time': array([4.70016266e-04, 6.57562879e-06, 4.72046148e-04, 2.15961208e-03,\n",
       "        4.68108731e-04, 4.70358829e-04, 1.41354944e-03]),\n",
       " 'mean_score_time': array([14.13528546, 14.53236977, 14.71659096, 15.87792913, 14.93379728,\n",
       "        14.87450067, 15.05140193]),\n",
       " 'std_score_time': array([0.07521686, 0.25402035, 0.15673464, 0.44688844, 0.47390882,\n",
       "        0.24355856, 0.30218583]),\n",
       " 'param_n_neighbors': masked_array(data=[3, 4, 5, 6, 7, 8, 9],\n",
       "              mask=[False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'n_neighbors': 3},\n",
       "  {'n_neighbors': 4},\n",
       "  {'n_neighbors': 5},\n",
       "  {'n_neighbors': 6},\n",
       "  {'n_neighbors': 7},\n",
       "  {'n_neighbors': 8},\n",
       "  {'n_neighbors': 9}],\n",
       " 'split0_test_score': array([0.9497295 , 0.94648356, 0.95189347, 0.95014565, 0.95289222,\n",
       "        0.95172701, 0.95272576]),\n",
       " 'split1_test_score': array([0.94606293, 0.94639587, 0.94980856, 0.94747794, 0.94889296,\n",
       "        0.94814383, 0.94789412]),\n",
       " 'split2_test_score': array([0.9492259 , 0.9480606 , 0.95147328, 0.94980856, 0.9510571 ,\n",
       "        0.95039121, 0.9519727 ]),\n",
       " 'mean_test_score': array([0.94833948, 0.94698   , 0.95105846, 0.94914408, 0.95094748,\n",
       "        0.9500874 , 0.95086425]),\n",
       " 'std_test_score': array([0.00162281, 0.00076492, 0.00090029, 0.00118612, 0.00163454,\n",
       "        0.00147853, 0.00212253]),\n",
       " 'rank_test_score': array([6, 7, 1, 5, 2, 4, 3]),\n",
       " 'split0_train_score': array([0.97136674, 0.96504079, 0.96732978, 0.96350092, 0.96574829,\n",
       "        0.96171134, 0.96283503]),\n",
       " 'split1_train_score': array([0.97432269, 0.96687336, 0.96841317, 0.96437638, 0.96504224,\n",
       "        0.96275334, 0.96354405]),\n",
       " 'split2_train_score': array([0.97353198, 0.96708144, 0.96695659, 0.96379375, 0.96450123,\n",
       "        0.96175455, 0.96167131]),\n",
       " 'mean_train_score': array([0.9730738 , 0.96633186, 0.96756651, 0.96389035, 0.96509725,\n",
       "        0.96207307, 0.96268346]),\n",
       " 'std_train_score': array([0.0012495 , 0.00091687, 0.00061776, 0.00036387, 0.0005106 ,\n",
       "        0.00048134, 0.00077202])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_knn.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver, el mejor está con K = 8, donde se consiguen unos aciertos de hasta el 95.1%, y de media un 95%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                3) SVM - Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "svm_classification = svm.SVC(kernel='linear', verbose = True)\n",
    "svm_classification.fit(x_train_sparse, y_train_sparse)\n",
    "prediccion_svm_clas = svm_classification.predict(x_test_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Clasificación SVM\")\n",
    "\n",
    "score_train_svm_classification = svm_classification.score(x_train_sparse, y_train_sparse)\n",
    "print(\"La puntuación del entrenamiento en tanto por 1 es de: {:.3f}\".format(score_train_svm_classification))\n",
    "\n",
    "score_test_svm_classification = svm_classification.score(x_test_sparse, y_test_sparse)\n",
    "print(\"La puntuación del test en tanto por 1 es de: {:.3f}\".format(score_test_svm_classification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados['svm_clas_train'] = score_train_svm_classification\n",
    "df_resultados['svm_clas_test'] = score_test_svm_classification\n",
    "print(confusion_matrix(y_test_sparse, prediccion_svm_clas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Ahora con kernel radial (rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classification_rbf = svm.SVC(kernel='rbf')\n",
    "svm_classification_rbf.fit(x_train_sparse, y_train_sparse)\n",
    "prediccion_svm_clas_rbf = svm_classification_rbf.predict(x_test_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Clasificación SVM con Kernel RBF\")\n",
    "\n",
    "score_train_svm_classification_rbf = svm_classification_rbf.score(x_train_sparse, y_train_sparse)\n",
    "print(\"La puntuación del entrenamiento en tanto por 1 es de: {:.3f}\".format(score_train_svm_classification_rbf))\n",
    "\n",
    "score_test_svm_classification_rbf = svm_classification_rbf.score(x_test_sparse, y_test_sparse)\n",
    "print(\"La puntuación del test en tanto por 1 es de: {:.3f}\".format(score_test_svm_classification_rbf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados['svm_clas_rbf_train'] = score_train_svm_classification_rbf\n",
    "df_resultados['svm_clas_rbf_test'] = score_test_svm_classification_rbf\n",
    "print(confusion_matrix(y_test_sparse, prediccion_svm_clas_rbf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Finalmente con Kernel Polinómico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classification_poly = svm.SVC(kernel='poly', degree=3)\n",
    "svm_classification_poly.fit(x_train_sparse, y_train_sparse)\n",
    "prediccion_svm_clas_poly = svm_classification_poly.predict(x_test_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Clasificación SVM con Kernel Polinómico de Grado 3\")\n",
    "\n",
    "score_train_svm_classification_poly = svm_classification_poly.score(x_train_sparse, y_train_sparse)\n",
    "print(\"La puntuación del entrenamiento en tanto por 1 es de: {:.3f}\".format(score_train_svm_classification_poly))\n",
    "\n",
    "score_test_svm_classification_poly = svm_classification_poly.score(x_test_sparse, y_test_sparse)\n",
    "print(\"La puntuación del test en tanto por 1 es de: {:.3f}\".format(score_test_svm_classification_poly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados['svm_clas_poly_train'] = score_train_svm_classification_poly\n",
    "df_resultados['svm_clas_poly_test'] = score_test_svm_classification_poly\n",
    "print(confusion_matrix(y_test_sparse, prediccion_svm_clas_poly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora con Malla para ver cuales son los mejores parámetros (o lineal o RBF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros = {\n",
    "    'kernel':('linear', 'rbf'),\n",
    "    'C':[1, 5]\n",
    "}\n",
    "\n",
    "svc_grid = svm.SVC(gamma=\"scale\")\n",
    "svc_grid = GridSearchCV(svc, parametros, cv=3)\n",
    "svc_grid_model = svc_grid.fit(x_train_sparse, y_train_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_svm_grid = svc_grid_model.predict(x_test_sparse)\n",
    "\n",
    "svc_grid_model.best_parameters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Clasificación SVM con Grid\")\n",
    "\n",
    "score_train_svm_grid = prediccion_svm_grid.score(x_train_sparse, y_train_sparse)\n",
    "print(\"La puntuación del entrenamiento en tanto por 1 es de: {:.3f}\".format(score_train_svm_grid))\n",
    "\n",
    "score_test_svm_grid = prediccion_svm_grid.score(x_test_sparse, y_test_sparse)\n",
    "print(\"La puntuación del test en tanto por 1 es de: {:.3f}\".format(score_test_svm_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                            4) Árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                Sin Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_alg = tree.DecisionTreeClassifier()\n",
    "tree_model = tree_alg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_tree = tree_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificación Tree sin CV\n",
      "La puntuación del entrenamiento en tanto por 1 es de: 1.000\n",
      "La puntuación del test en tanto por 1 es de: 0.843\n"
     ]
    }
   ],
   "source": [
    "print(\"Clasificación Tree sin CV\")\n",
    "\n",
    "score_train_tree_classification = tree_model.score(x_train, y_train)\n",
    "print(\"La puntuación del entrenamiento en tanto por 1 es de: {:.3f}\".format(score_train_tree_classification))\n",
    "\n",
    "score_test_tree_classification = tree_model.score(x_test, y_test)\n",
    "print(\"La puntuación del test en tanto por 1 es de: {:.3f}\".format(score_test_tree_classification))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                Con Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9654368932038835,\n",
       " 0.9638834951456311,\n",
       " 0.9636752136752137,\n",
       " 0.9632938434647504,\n",
       " 0.9632867132867133,\n",
       " 0.9630924630924631,\n",
       " 0.9615459312487862,\n",
       " 0.9613517187803456,\n",
       " 0.9588349514563107,\n",
       " 0.9564964070693338]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "tree_cv = tree.DecisionTreeClassifier(random_state=97)\n",
    "sorted(cross_val_score(tree_cv, games_ml, games.winner, cv=10), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver:\n",
    "    \n",
    "Sin CV se ha obtenido un overfitting que ha hecho que la puntuación de test baje hasta 84%\n",
    "\n",
    "Con CV se obtiene hasta un 96.5% de exactitud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                              5) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10705208 0.02685478 0.00135981 ... 0.00013135 0.00021605 0.00020362]\n"
     ]
    }
   ],
   "source": [
    "randomForest = RandomForestClassifier(n_estimators=1000, max_depth=3, random_state=97)\n",
    "randomForest_model = randomForest.fit(x_train, y_train)\n",
    "\n",
    "print(randomForest_model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_randomForest = randomForest_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificación Random Forest\n",
      "La puntuación del entrenamiento en tanto por 1 es de: 0.897\n",
      "La puntuación del test en tanto por 1 es de: 0.886\n"
     ]
    }
   ],
   "source": [
    "print(\"Clasificación Random Forest\")\n",
    "\n",
    "score_train_rf_classification = randomForest_model.score(x_train, y_train)\n",
    "print(\"La puntuación del entrenamiento en tanto por 1 es de: {:.3f}\".format(score_train_rf_classification))\n",
    "\n",
    "score_test_rf_classification = randomForest_model.score(x_test, y_test)\n",
    "print(\"La puntuación del test en tanto por 1 es de: {:.3f}\".format(score_test_rf_classification))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aumentemos la profundidad de los árboles. Esto puede dar lugar a overfitting, pero hay margen todavía"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.40818655e-01 1.80825709e-02 7.51341570e-04 ... 5.31014883e-05\n",
      " 3.14990556e-04 1.06526721e-04]\n"
     ]
    }
   ],
   "source": [
    "randomForest = RandomForestClassifier(n_estimators=1000, max_depth=5, random_state=97)\n",
    "randomForest_model = randomForest.fit(x_train, y_train)\n",
    "\n",
    "print(randomForest_model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_randomForest = randomForest_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificación Random Forest Mayor Profundidad\n",
      "La puntuación del entrenamiento en tanto por 1 es de: 0.900\n",
      "La puntuación del test en tanto por 1 es de: 0.887\n"
     ]
    }
   ],
   "source": [
    "print(\"Clasificación Random Forest Mayor Profundidad\")\n",
    "\n",
    "score_train_rf_classification = randomForest_model.score(x_train, y_train)\n",
    "print(\"La puntuación del entrenamiento en tanto por 1 es de: {:.3f}\".format(score_train_rf_classification))\n",
    "\n",
    "score_test_rf_classification = randomForest_model.score(x_test, y_test)\n",
    "print(\"La puntuación del test en tanto por 1 es de: {:.3f}\".format(score_test_rf_classification))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para asegurarse de que se coge la mejor opción, se puede hacer una búsqueda a través de una malla para obtener los mejores valores, y entonces aplicarlos al algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForest_grid = RandomForestClassifier(random_state=97)\n",
    "\n",
    "grid = { \n",
    "    'n_estimators': [2000, 2500],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'max_depth' : [7,8,9,10],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "#CV por defecto de 3\n",
    "randomForest = GridSearchCV(estimator=randomForest_grid, param_grid=grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\jorge\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 10,\n",
       " 'max_features': 'auto',\n",
       " 'n_estimators': 2500}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomForest.fit(x_train_sparse, y_train_sparse)\n",
    "\n",
    "randomForest.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificación Random Forest Grid CV 3\n",
      "La puntuación del entrenamiento en tanto por 1 es de: 0.944\n",
      "La puntuación del test en tanto por 1 es de: 0.937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\jorge\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\jorge\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\jorge\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\jorge\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\jorge\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([13.46597401, 16.62716913, 13.56192072, 16.68047277, 16.13811501,\n",
       "        20.18316452, 16.22740102, 20.2044584 , 19.30630445, 23.98796399,\n",
       "        19.36161192, 23.9999605 , 22.83528813, 28.48206425, 22.82363002,\n",
       "        28.34082103, 13.47263583, 16.75709128, 13.46464157, 16.73444017,\n",
       "        16.18408823, 20.03689615, 16.2428685 , 20.17414252, 19.25166599,\n",
       "        24.01727684, 19.23967298, 23.98396905, 22.67805346, 28.33248814,\n",
       "        22.72070217, 28.23386312]),\n",
       " 'std_fit_time': array([0.18627821, 0.3514176 , 0.3421116 , 0.37910962, 0.25923039,\n",
       "        0.43771108, 0.36347484, 0.26932085, 0.36051934, 0.33371684,\n",
       "        0.34919615, 0.38404307, 0.21648717, 0.30588337, 0.45977704,\n",
       "        0.44393693, 0.18358662, 0.29355298, 0.30414542, 0.27312208,\n",
       "        0.3215699 , 0.34823741, 0.27518928, 0.36701549, 0.28277839,\n",
       "        0.47369124, 0.31238269, 0.3127709 , 0.25307887, 0.34178722,\n",
       "        0.1919976 , 0.3559623 ]),\n",
       " 'mean_score_time': array([2.69612622, 3.28812496, 2.64616172, 3.37307493, 2.82971398,\n",
       "        3.42737977, 2.7137835 , 3.38006949, 2.79374186, 3.48700857,\n",
       "        2.80706668, 3.45635907, 2.84571234, 3.62793501, 2.9209977 ,\n",
       "        3.65390881, 2.68946926, 3.41438643, 2.7251099 , 3.37540181,\n",
       "        2.73643327, 3.41038338, 2.77274585, 3.44103408, 2.79773577,\n",
       "        3.50100088, 2.82372006, 3.5179925 , 2.91733344, 3.65757704,\n",
       "        2.90100177, 3.61894035]),\n",
       " 'std_score_time': array([0.03060183, 0.04099457, 0.0118875 , 0.02639834, 0.07115587,\n",
       "        0.03398177, 0.02888697, 0.0253752 , 0.02287766, 0.0139205 ,\n",
       "        0.04091427, 0.03435284, 0.01032858, 0.03642472, 0.08430413,\n",
       "        0.0661532 , 0.02529204, 0.06612514, 0.01928253, 0.02359809,\n",
       "        0.03731926, 0.0365248 , 0.0506288 , 0.01066284, 0.0221435 ,\n",
       "        0.03724389, 0.01306422, 0.01881601, 0.00588453, 0.0540806 ,\n",
       "        0.02421712, 0.05482405]),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[7, 7, 7, 7, 8, 8, 8, 8, 9, 9, 9, 9, 10, 10, 10, 10, 7,\n",
       "                    7, 7, 7, 8, 8, 8, 8, 9, 9, 9, 9, 10, 10, 10, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=['auto', 'auto', 'sqrt', 'sqrt', 'auto', 'auto', 'sqrt',\n",
       "                    'sqrt', 'auto', 'auto', 'sqrt', 'sqrt', 'auto', 'auto',\n",
       "                    'sqrt', 'sqrt', 'auto', 'auto', 'sqrt', 'sqrt', 'auto',\n",
       "                    'auto', 'sqrt', 'sqrt', 'auto', 'auto', 'sqrt', 'sqrt',\n",
       "                    'auto', 'auto', 'sqrt', 'sqrt'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[2000, 2500, 2000, 2500, 2000, 2500, 2000, 2500, 2000,\n",
       "                    2500, 2000, 2500, 2000, 2500, 2000, 2500, 2000, 2500,\n",
       "                    2000, 2500, 2000, 2500, 2000, 2500, 2000, 2500, 2000,\n",
       "                    2500, 2000, 2500, 2000, 2500],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 2000},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 2500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 2000},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 2500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 2000},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 2500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 2000},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 2500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 2000},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 2500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 2000},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 2500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 2000},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 2500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 2000},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 2500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 2000},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 2500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 2000},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 2500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 2000},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 2500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 2000},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 2500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 2000},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 2500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 2000},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 2500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 2000},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 2500},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 2000},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 2500}],\n",
       " 'split0_test_score': array([0.93216812, 0.93208489, 0.93216812, 0.93208489, 0.9340824 ,\n",
       "        0.93366625, 0.9340824 , 0.93366625, 0.93624636, 0.93649605,\n",
       "        0.93624636, 0.93649605, 0.93674573, 0.93649605, 0.93674573,\n",
       "        0.93649605, 0.93216812, 0.93258427, 0.93216812, 0.93258427,\n",
       "        0.93300042, 0.93366625, 0.93300042, 0.93366625, 0.93524761,\n",
       "        0.9354973 , 0.93524761, 0.9354973 , 0.93724511, 0.93724511,\n",
       "        0.93724511, 0.93724511]),\n",
       " 'split1_test_score': array([0.93008157, 0.93041452, 0.93008157, 0.93041452, 0.9308307 ,\n",
       "        0.93141335, 0.9308307 , 0.93141335, 0.93249542, 0.93324455,\n",
       "        0.93249542, 0.93324455, 0.93574163, 0.93582487, 0.93574163,\n",
       "        0.93582487, 0.93016481, 0.93066423, 0.93016481, 0.93066423,\n",
       "        0.93041452, 0.93066423, 0.93041452, 0.93066423, 0.93166306,\n",
       "        0.93182953, 0.93166306, 0.93182953, 0.93282837, 0.93324455,\n",
       "        0.93282837, 0.93324455]),\n",
       " 'split2_test_score': array([0.93582487, 0.93590811, 0.93582487, 0.93590811, 0.93790578,\n",
       "        0.9377393 , 0.93790578, 0.9377393 , 0.93940403, 0.9395705 ,\n",
       "        0.93940403, 0.9395705 , 0.94065257, 0.94131846, 0.94065257,\n",
       "        0.94131846, 0.93499251, 0.93499251, 0.93499251, 0.93499251,\n",
       "        0.93557516, 0.93582487, 0.93557516, 0.93582487, 0.93882138,\n",
       "        0.93932079, 0.93882138, 0.93932079, 0.94073581, 0.94056934,\n",
       "        0.94073581, 0.94056934]),\n",
       " 'mean_test_score': array([0.93269151, 0.93280249, 0.93269151, 0.93280249, 0.93427295,\n",
       "        0.93427295, 0.93427295, 0.93427295, 0.93604861, 0.93643703,\n",
       "        0.93604861, 0.93643703, 0.93771329, 0.93787975, 0.93771329,\n",
       "        0.93787975, 0.93244181, 0.932747  , 0.93244181, 0.932747  ,\n",
       "        0.9329967 , 0.93338512, 0.9329967 , 0.93338512, 0.93524401,\n",
       "        0.93554921, 0.93524401, 0.93554921, 0.93693644, 0.93701967,\n",
       "        0.93693644, 0.93701967]),\n",
       " 'std_test_score': array([0.00237369, 0.00229941, 0.00237369, 0.00229941, 0.00289149,\n",
       "        0.00261792, 0.00289149, 0.00261792, 0.00282385, 0.00258286,\n",
       "        0.00282385, 0.00258286, 0.00211839, 0.00244687, 0.00211839,\n",
       "        0.00244687, 0.00198035, 0.00177073, 0.00198035, 0.00177073,\n",
       "        0.0021068 , 0.00211615, 0.0021068 , 0.00211615, 0.00292233,\n",
       "        0.00305847, 0.00292233, 0.00305847, 0.00323553, 0.00299454,\n",
       "        0.00323553, 0.00299454]),\n",
       " 'rank_test_score': array([29, 25, 29, 25, 17, 17, 17, 17, 11,  9, 11,  9,  3,  1,  3,  1, 31,\n",
       "        27, 31, 27, 23, 21, 23, 21, 15, 13, 15, 13,  7,  5,  7,  5]),\n",
       " 'split0_train_score': array([0.93524222, 0.93549193, 0.93524222, 0.93549193, 0.9381971 ,\n",
       "        0.93853005, 0.9381971 , 0.93853005, 0.94190112, 0.94181788,\n",
       "        0.94190112, 0.94181788, 0.94427335, 0.94402364, 0.94427335,\n",
       "        0.94402364, 0.93594973, 0.93574163, 0.93594973, 0.93574163,\n",
       "        0.93707341, 0.93744798, 0.93707341, 0.93744798, 0.93994506,\n",
       "        0.93998668, 0.93994506, 0.93998668, 0.94319128, 0.94294157,\n",
       "        0.94319128, 0.94294157]),\n",
       " 'split1_train_score': array([0.93711765, 0.93728412, 0.93711765, 0.93728412, 0.93899039,\n",
       "        0.9397811 , 0.93899039, 0.9397811 , 0.94281909, 0.94286071,\n",
       "        0.94281909, 0.94286071, 0.94623164, 0.94643972, 0.94623164,\n",
       "        0.94643972, 0.93657664, 0.93686795, 0.93657664, 0.93686795,\n",
       "        0.93915685, 0.93844937, 0.93915685, 0.93844937, 0.94115444,\n",
       "        0.94123767, 0.94115444, 0.94123767, 0.94469183, 0.94502476,\n",
       "        0.94469183, 0.94502476]),\n",
       " 'split2_train_score': array([0.93366349, 0.93399642, 0.93366349, 0.93399642, 0.93782513,\n",
       "        0.93828291, 0.93782513, 0.93828291, 0.94086312, 0.94165383,\n",
       "        0.94086312, 0.94165383, 0.9436098 , 0.94444213, 0.9436098 ,\n",
       "        0.94444213, 0.93328894, 0.93303924, 0.93328894, 0.93303924,\n",
       "        0.93545299, 0.93591077, 0.93545299, 0.93591077, 0.94028049,\n",
       "        0.94044696, 0.94028049, 0.94044696, 0.94348496, 0.94394274,\n",
       "        0.94348496, 0.94394274]),\n",
       " 'mean_train_score': array([0.93534112, 0.93559082, 0.93534112, 0.93559082, 0.93833754,\n",
       "        0.93886468, 0.93833754, 0.93886468, 0.94186111, 0.94211081,\n",
       "        0.94186111, 0.94211081, 0.94470493, 0.9449685 , 0.94470493,\n",
       "        0.9449685 , 0.93527177, 0.93521628, 0.93527177, 0.93521628,\n",
       "        0.93722775, 0.93726938, 0.93722775, 0.93726938, 0.94046   ,\n",
       "        0.9405571 , 0.94046   , 0.9405571 , 0.94378935, 0.94396969,\n",
       "        0.94378935, 0.94396969]),\n",
       " 'std_train_score': array([0.00141189, 0.00134402, 0.00141189, 0.00134402, 0.00048597,\n",
       "        0.00065581, 0.00048597, 0.00065581, 0.00079902, 0.00053447,\n",
       "        0.00079902, 0.00053447, 0.00111301, 0.00105425, 0.00111301,\n",
       "        0.00105425, 0.00142524, 0.0016066 , 0.00142524, 0.0016066 ,\n",
       "        0.00151603, 0.00104405, 0.00151603, 0.00104405, 0.00050978,\n",
       "        0.00051662, 0.00050978, 0.00051662, 0.00064931, 0.00085067,\n",
       "        0.00064931, 0.00085067])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Clasificación Random Forest Grid CV 3\")\n",
    "\n",
    "score_train_rf_classification = randomForest.score(x_train_sparse, y_train_sparse)\n",
    "print(\"La puntuación del entrenamiento en tanto por 1 es de: {:.3f}\".format(score_train_rf_classification))\n",
    "\n",
    "score_test_rf_classification = randomForest.score(x_test_sparse, y_test_sparse)\n",
    "print(\"La puntuación del test en tanto por 1 es de: {:.3f}\".format(score_test_rf_classification))\n",
    "\n",
    "resultados = randomForest.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ante la vista de que el máximo es el que me está dando mayores resultados, voy a hacer un grid a partir de este máximo para ver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForest_grid = RandomForestClassifier(random_state=97)\n",
    "\n",
    "grid = { \n",
    "    'n_estimators': [2500, 3200],\n",
    "    'max_features': ['auto'],\n",
    "    'max_depth' : [19, 20, 21, 22, 23],\n",
    "    'criterion' : ['gini']\n",
    "}\n",
    "\n",
    "#CV por defecto de 3\n",
    "randomForest = GridSearchCV(estimator=randomForest_grid, param_grid=grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\jorge\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 23,\n",
       " 'max_features': 'auto',\n",
       " 'n_estimators': 3200}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomForest.fit(x_train_sparse, y_train_sparse)\n",
    "\n",
    "randomForest.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificación Random Forest Grid CV 3\n",
      "La puntuación del entrenamiento en tanto por 1 es de: 0.985\n",
      "La puntuación del test en tanto por 1 es de: 0.955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\jorge\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\jorge\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\jorge\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\jorge\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\jorge\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 84.09729091, 108.03495336,  91.92816257, 118.19215091,\n",
       "         99.7969838 , 130.81561128, 109.00906634, 140.21024338,\n",
       "        117.08578261, 149.58988126]),\n",
       " 'std_fit_time': array([1.0607448 , 0.98821738, 0.87014215, 0.89157012, 0.9942076 ,\n",
       "        1.99466667, 1.13540899, 1.14015021, 0.66291745, 1.43361468]),\n",
       " 'mean_score_time': array([4.66600092, 6.08352518, 4.84556953, 6.32671968, 5.04312007,\n",
       "        6.68085003, 5.52651016, 6.90405234, 5.3216335 , 7.13892245]),\n",
       " 'std_score_time': array([0.02215755, 0.04836546, 0.01790242, 0.06002251, 0.07975375,\n",
       "        0.03491178, 0.27675383, 0.02727499, 0.07107612, 0.10142101]),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[19, 19, 20, 20, 21, 21, 22, 22, 23, 23],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=['auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[2500, 3200, 2500, 3200, 2500, 3200, 2500, 3200, 2500,\n",
       "                    3200],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'gini',\n",
       "   'max_depth': 19,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 2500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 19,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 3200},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 2500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 3200},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 21,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 2500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 21,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 3200},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 22,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 2500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 22,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 3200},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 23,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 2500},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 23,\n",
       "   'max_features': 'auto',\n",
       "   'n_estimators': 3200}],\n",
       " 'split0_test_score': array([0.95330836, 0.95314191, 0.95380774, 0.95414066, 0.9559717 ,\n",
       "        0.95605493, 0.95688722, 0.95705368, 0.95763629, 0.95805243]),\n",
       " 'split1_test_score': array([0.95030797, 0.95039121, 0.95122357, 0.95163975, 0.9519727 ,\n",
       "        0.95205593, 0.95330448, 0.95322124, 0.95372066, 0.95397037]),\n",
       " 'split2_test_score': array([0.95488597, 0.95455302, 0.95596804, 0.95563509, 0.95613451,\n",
       "        0.9558848 , 0.95721658, 0.95721658, 0.95796571, 0.95821542]),\n",
       " 'mean_test_score': array([0.95283411, 0.95269539, 0.95366645, 0.95380518, 0.95469301,\n",
       "        0.95466526, 0.95580279, 0.95583054, 0.95644092, 0.95674611]),\n",
       " 'std_test_score': array([0.00189878, 0.00172812, 0.00193947, 0.00164823, 0.00192466,\n",
       "        0.00184634, 0.00177165, 0.00184621, 0.00192817, 0.00196383]),\n",
       " 'rank_test_score': array([ 9, 10,  8,  7,  5,  6,  4,  3,  2,  1]),\n",
       " 'split0_train_score': array([0.97594473, 0.97681871, 0.98056434, 0.98106376, 0.98455968,\n",
       "        0.98510072, 0.98763942, 0.98763942, 0.99051107, 0.99046945]),\n",
       " 'split1_train_score': array([0.97519664, 0.97519664, 0.97781847, 0.9781514 , 0.98143909,\n",
       "        0.98160556, 0.9850181 , 0.98505972, 0.98697407, 0.98726539]),\n",
       " 'split2_train_score': array([0.97748554, 0.97744392, 0.98077323, 0.98098131, 0.98327022,\n",
       "        0.98343668, 0.98555912, 0.98597528, 0.98909651, 0.98963752]),\n",
       " 'mean_train_score': array([0.97620897, 0.97648642, 0.97971868, 0.98006549, 0.98308966,\n",
       "        0.98338099, 0.98607221, 0.98622481, 0.98886055, 0.98912412]),\n",
       " 'std_train_score': array([0.00095294, 0.00094706, 0.00134636, 0.00135389, 0.00128035,\n",
       "        0.00142743, 0.00112998, 0.00106784, 0.00145358, 0.0013575 ])}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Clasificación Random Forest Grid CV 3\")\n",
    "\n",
    "score_train_rf_classification = randomForest.score(x_train_sparse, y_train_sparse)\n",
    "print(\"La puntuación del entrenamiento en tanto por 1 es de: {:.3f}\".format(score_train_rf_classification))\n",
    "\n",
    "score_test_rf_classification = randomForest.score(x_test_sparse, y_test_sparse)\n",
    "print(\"La puntuación del test en tanto por 1 es de: {:.3f}\".format(score_test_rf_classification))\n",
    "\n",
    "randomForest.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras hacer varias pruebas, y con el aumento de árboles y su profundidad como problema computacional, con un 95,5% de acierto creo que es suficiente.\n",
    "\n",
    "Si se qusiera mejorar, según arrojan los resultados, el aumento de la profundidad de los árboles quizás arroje mejores resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                            6) Descenso del Gradiente Estocástico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\jorge\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "sgd = SGDClassifier(max_iter=1000, random_state=97)\n",
    "sgd_model = sgd.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_sgd = sgd_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificación SGD\n",
      "La puntuación del entrenamiento en tanto por 1 es de: 0.964\n",
      "La puntuación del test en tanto por 1 es de: 0.920\n"
     ]
    }
   ],
   "source": [
    "print(\"Clasificación SGD\")\n",
    "\n",
    "score_train_sgd_classification = sgd_model.score(x_train, y_train)\n",
    "print(\"La puntuación del entrenamiento en tanto por 1 es de: {:.3f}\".format(score_train_sgd_classification))\n",
    "\n",
    "score_test_sgd_classification = sgd_model.score(x_test, y_test)\n",
    "print(\"La puntuación del test en tanto por 1 es de: {:.3f}\".format(score_test_sgd_classification))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                              7) Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes = GaussianNB()\n",
    "naive_bayes_model = naive_bayes.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_naive_bayes = naive_bayes_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificación Naive Bayes\n",
      "La puntuación del entrenamiento en tanto por 1 es de: 0.788\n",
      "La puntuación del test en tanto por 1 es de: 0.768\n"
     ]
    }
   ],
   "source": [
    "print(\"Clasificación Naive Bayes\")\n",
    "\n",
    "score_train_nb_classification = naive_bayes_model.score(x_train, y_train)\n",
    "print(\"La puntuación del entrenamiento en tanto por 1 es de: {:.3f}\".format(score_train_nb_classification))\n",
    "\n",
    "score_test_nb_classification = naive_bayes_model.score(x_test, y_test)\n",
    "print(\"La puntuación del test en tanto por 1 es de: {:.3f}\".format(score_test_nb_classification))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                                 8) AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_boost = AdaBoostClassifier()\n",
    "ada_boost_model = ada_boost.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_ada_boost = ada_boost_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificación Ada Boost\n",
      "La puntuación del entrenamiento en tanto por 1 es de: 0.921\n",
      "La puntuación del test en tanto por 1 es de: 0.912\n"
     ]
    }
   ],
   "source": [
    "print(\"Clasificación Ada Boost\")\n",
    "\n",
    "score_train_adaboost_classification = ada_boost_model.score(x_train, y_train)\n",
    "print(\"La puntuación del entrenamiento en tanto por 1 es de: {:.3f}\".format(score_train_adaboost_classification))\n",
    "\n",
    "score_test_adaboost_classification = ada_boost_model.score(x_test, y_test)\n",
    "print(\"La puntuación del test en tanto por 1 es de: {:.3f}\".format(score_test_adaboost_classification))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                         9) Gradient Tree Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_boosting = GradientBoostingClassifier()\n",
    "gradient_boosting_model = gradient_boosting.fit(x_train_sparse, y_train_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_gradient_boosting = gradient_boosting_model.predict(x_test_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificación Gradient Boosting\n",
      "La puntuación del entrenamiento en tanto por 1 es de: 0.974\n",
      "La puntuación del test en tanto por 1 es de: 0.974\n"
     ]
    }
   ],
   "source": [
    "print(\"Clasificación Gradient Boosting\")\n",
    "\n",
    "score_train_gradientBoosting_classification = gradient_boosting_model.score(x_train_sparse, y_train_sparse)\n",
    "print(\"La puntuación del entrenamiento en tanto por 1 es de: {:.3f}\".format(score_train_gradientBoosting_classification))\n",
    "\n",
    "score_test_gradientBoosting_classification = gradient_boosting_model.score(x_test_sparse, y_test_sparse)\n",
    "print(\"La puntuación del test en tanto por 1 es de: {:.3f}\".format(score_train_gradientBoosting_classification))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                                 10) K_Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dos clusters, uno para victoria y uno para derrota\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=97)\n",
    "\n",
    "kmeans_model = kmeans.fit(x_train_sparse, y_train_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.45411778e+00, 1.41626079e+00, 1.14356874e+00, ...,\n",
       "        4.42771751e-04, 4.42771751e-04, 1.32831525e-03],\n",
       "       [1.49179416e+00, 1.49279555e+00, 1.47571627e+00, ...,\n",
       "        3.33796940e-04, 3.89429764e-04, 1.66898470e-03]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_kmeans = kmeans_model.predict(x_test_sparse)\n",
    "\n",
    "kmeans_model.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                        11) Clustering Espectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_spectral = SpectralClustering(n_clusters=2, affinity='nearest_neighbors', assign_labels='kmeans')\n",
    "labels = model_spectral.fit(x_train_sparse, y_train_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                        12) Clustering Jerárquico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "range object index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-118a9b1715bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabelList\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mdistance_sort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'descending'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             show_leaf_counts=True)\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"imagenes/clustering jerárquico.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\jorge\\Anaconda3\\lib\\site-packages\\scipy\\cluster\\hierarchy.py\u001b[0m in \u001b[0;36mdendrogram\u001b[1;34m(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color)\u001b[0m\n\u001b[0;32m   2499\u001b[0m         \u001b[0mcontraction_marks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontraction_marks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2500\u001b[0m         \u001b[0mlink_color_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlink_color_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2501\u001b[1;33m         above_threshold_color=above_threshold_color)\n\u001b[0m\u001b[0;32m   2502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2503\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_plot\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\jorge\\Anaconda3\\lib\\site-packages\\scipy\\cluster\\hierarchy.py\u001b[0m in \u001b[0;36m_dendrogram_calculate_info\u001b[1;34m(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, i, iv, ivl, n, icoord_list, dcoord_list, lvs, mhr, current_color, color_list, currently_below_threshold, leaf_label_func, level, contraction_marks, link_color_func, above_threshold_color)\u001b[0m\n\u001b[0;32m   2752\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_marks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontraction_marks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2753\u001b[0m             \u001b[0mlink_color_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlink_color_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2754\u001b[1;33m             above_threshold_color=above_threshold_color)\n\u001b[0m\u001b[0;32m   2755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2756\u001b[0m     \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\jorge\\Anaconda3\\lib\\site-packages\\scipy\\cluster\\hierarchy.py\u001b[0m in \u001b[0;36m_dendrogram_calculate_info\u001b[1;34m(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, i, iv, ivl, n, icoord_list, dcoord_list, lvs, mhr, current_color, color_list, currently_below_threshold, leaf_label_func, level, contraction_marks, link_color_func, above_threshold_color)\u001b[0m\n\u001b[0;32m   2752\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_marks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontraction_marks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2753\u001b[0m             \u001b[0mlink_color_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlink_color_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2754\u001b[1;33m             above_threshold_color=above_threshold_color)\n\u001b[0m\u001b[0;32m   2755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2756\u001b[0m     \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\jorge\\Anaconda3\\lib\\site-packages\\scipy\\cluster\\hierarchy.py\u001b[0m in \u001b[0;36m_dendrogram_calculate_info\u001b[1;34m(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, i, iv, ivl, n, icoord_list, dcoord_list, lvs, mhr, current_color, color_list, currently_below_threshold, leaf_label_func, level, contraction_marks, link_color_func, above_threshold_color)\u001b[0m\n\u001b[0;32m   2664\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2665\u001b[0m         _append_singleton_leaf_node(Z, p, n, level, lvs, ivl,\n\u001b[1;32m-> 2666\u001b[1;33m                                     leaf_label_func, i, labels)\n\u001b[0m\u001b[0;32m   2667\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0miv\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m5.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\jorge\\Anaconda3\\lib\\site-packages\\scipy\\cluster\\hierarchy.py\u001b[0m in \u001b[0;36m_append_singleton_leaf_node\u001b[1;34m(Z, p, n, level, lvs, ivl, leaf_label_func, i, labels)\u001b[0m\n\u001b[0;32m   2534\u001b[0m             \u001b[1;31m# for the leaf nodes, use it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2535\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2536\u001b[1;33m                 \u001b[0mivl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2537\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2538\u001b[0m                 \u001b[1;31m# Otherwise, use the id as the label for the leaf.x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: range object index out of range"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function install_repl_displayhook.<locals>.post_execute at 0x0000014E006C6620> (for post_execute):\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Image size of 518400x362880 pixels is too large. It must be less than 2^16 in each direction.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mD:\\Users\\jorge\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mpost_execute\u001b[1;34m()\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mpost_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_interactive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m                     \u001b[0mdraw_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[1;31m# IPython >= 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\jorge\\Anaconda3\\lib\\site-packages\\matplotlib\\_pylab_helpers.py\u001b[0m in \u001b[0;36mdraw_all\u001b[1;34m(cls, force)\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mf_mgr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mforce\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mf_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstale\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m                 \u001b[0mf_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[0matexit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGcf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroy_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\jorge\\Anaconda3\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mdraw_idle\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1897\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_idle_drawing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1898\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_idle_draw_cntx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1899\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1900\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1901\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdraw_cursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\jorge\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    394\u001b[0m         \u001b[0mDraw\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfigure\u001b[0m \u001b[0musing\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m         \"\"\"\n\u001b[1;32m--> 396\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrenderer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleared\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m         \u001b[1;31m# acquire a lock on the shared font cache\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[0mRendererAgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\jorge\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mget_renderer\u001b[1;34m(self, cleared)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mneed_new_renderer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrenderer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRendererAgg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    418\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lastKey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mcleared\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\jorge\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, width, height, dpi)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_renderer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_RendererAgg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filter_renderers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Image size of 518400x362880 pixels is too large. It must be less than 2^16 in each direction."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 518400x362880 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "linked = linkage(dataframe_ml_09, 'single')\n",
    "\n",
    "labelList = range(1, 2)\n",
    "\n",
    "plt.figure(figsize=(7200, 5040))  \n",
    "dendrogram(linked,  \n",
    "            orientation='top',\n",
    "            labels=labelList,\n",
    "            distance_sort='descending',\n",
    "            show_leaf_counts=True)\n",
    "\n",
    "plt.savefig(\"imagenes/clustering jerárquico.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                        13) Reglas de Asociación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install apyori\n",
    "\n",
    "from apyori import apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "association_rules = apriori(games_ml, min_support=0.0045, min_confidence=0.2, min_lift=3, min_length=2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-cfd0b95c3b99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massociation_rules\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "list(association_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                        14) Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Inicialización\n",
    "model = Sequential()\n",
    "\n",
    "# Input \n",
    "model.add(Dense(5, activation='relu', input_shape=(11,)))\n",
    "\n",
    "# Hidden\n",
    "model.add(Dense(12, activation='relu'))\n",
    "\n",
    "# Output\n",
    "# Sigmoide para que sean porcentajes\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics='accuracy')\n",
    "                   \n",
    "model.fit(x_train_sparse, y_train_sparse, epochs=10, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_deep = model.predict(x_test_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puntuacion_deep = model.evaluate(x_test_sparse, y_test_sparse, verbose=1)\n",
    "\n",
    "print(puntuacion_deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test_sparse, y_pred_sparse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
